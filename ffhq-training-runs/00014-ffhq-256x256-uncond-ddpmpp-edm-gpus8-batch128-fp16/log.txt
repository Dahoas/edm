Loading dataset...
Constructing network...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
/mnt/nvme/home/alex/repos/diffusion/edm/training/networks.py:166: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:31.)
  x_ft = torch.fft.rfft2(x)

EDMPrecond            Parameters  Buffers  Output shape         Datatype
---                   ---         ---      ---                  ---     
model.map_noise       -           -        [16, 128]            float32 
model.map_layer0      66048       -        [16, 512]            float32 
model.map_layer1      262656      -        [16, 512]            float32 
model.enc.0_conv      114176      -        [16, 128, 256, 256]  float16 
model.enc.0_block0    9798528     -        [16, 128, 256, 256]  float16 
model.enc.0_block1    9798528     -        [16, 128, 256, 256]  float16 
model.enc.0_block2    9798528     -        [16, 128, 256, 256]  float16 
model.enc.0_block3    9798528     -        [16, 128, 256, 256]  float16 
model.enc.1_down      2999296     8        [16, 128, 128, 128]  float16 
model.enc.1_block0    8914688     -        [16, 256, 128, 128]  float16 
model.enc.1_block1    11798272    -        [16, 256, 128, 128]  float16 
model.enc.1_block2    11798272    -        [16, 256, 128, 128]  float16 
model.enc.1_block3    11798272    -        [16, 256, 128, 128]  float16 
model.enc.2_down      4524032     8        [16, 256, 64, 64]    float16 
model.enc.2_block0    4721920     -        [16, 256, 64, 64]    float16 
model.enc.2_block1    4721920     -        [16, 256, 64, 64]    float16 
model.enc.2_block2    4721920     -        [16, 256, 64, 64]    float16 
model.enc.2_block3    4721920     -        [16, 256, 64, 64]    float16 
model.enc.3_down      1378304     8        [16, 256, 32, 32]    float16 
model.enc.3_block0    1312512     -        [16, 256, 32, 32]    float16 
model.enc.3_block1    1312512     -        [16, 256, 32, 32]    float16 
model.enc.3_block2    1312512     -        [16, 256, 32, 32]    float16 
model.enc.3_block3    1312512     -        [16, 256, 32, 32]    float16 
model.dec.3_in0       1576192     -        [16, 256, 32, 32]    float16 
model.dec.3_in1       1312512     -        [16, 256, 32, 32]    float16 
model.dec.3_block0    2034176     -        [16, 256, 32, 32]    float16 
model.dec.3_block1    2034176     -        [16, 256, 32, 32]    float16 
model.dec.3_block2    2034176     -        [16, 256, 32, 32]    float16 
model.dec.3_block3    2034176     -        [16, 256, 32, 32]    float16 
model.dec.3_block4    2034176     -        [16, 256, 32, 32]    float16 
model.dec.2_up        1378304     8        [16, 256, 64, 64]    float16 
model.dec.2_block0    2034176     -        [16, 256, 64, 64]    float16 
model.dec.2_block1    2034176     -        [16, 256, 64, 64]    float16 
model.dec.2_block2    2034176     -        [16, 256, 64, 64]    float16 
model.dec.2_block3    2034176     -        [16, 256, 64, 64]    float16 
model.dec.2_block4    2297856     -        [16, 256, 64, 64]    float16 
model.dec.1_up        11864064    8        [16, 256, 128, 128]  float16 
model.dec.1_block0    17762816    -        [16, 256, 128, 128]  float16 
model.dec.1_block1    17762816    -        [16, 256, 128, 128]  float16 
model.dec.1_block2    17762816    -        [16, 256, 128, 128]  float16 
model.dec.1_block3    17762816    -        [16, 256, 128, 128]  float16 
model.dec.1_block4    14813440    -        [16, 256, 128, 128]  float16 
model.dec.0_up        39127040    8        [16, 256, 256, 256]  float16 
model.dec.0_block0    19580416    -        [16, 128, 256, 256]  float16 
model.dec.0_block1    14697728    -        [16, 128, 256, 256]  float16 
model.dec.0_block2    14697728    -        [16, 128, 256, 256]  float16 
model.dec.0_block3    14697728    -        [16, 128, 256, 256]  float16 
model.dec.0_block4    14697728    -        [16, 128, 256, 256]  float16 
model.dec.0_aux_norm  256         -        [16, 128, 256, 256]  float16 
model.dec.0_aux_conv  114051      -        [16, 3, 256, 256]    float16 
model                 1152        -        [16, 3, 256, 256]    float16 
<top-level>           -           -        [16, 3, 256, 256]    float32 
---                   ---         ---      ---                  ---     
Total                 357200899   48       -                    -       

Setting up optimizer...
Training for 200000 kimg...

tick 0     kimg 0.1       time 40s          sec/tick 24.6    sec/kimg 192.45  maintenance 15.3   cpumem 3.31   gpumem 69.64  reserved 74.91 
tick 1     kimg 50.2      time 10m 04s      sec/tick 561.4   sec/kimg 11.22   maintenance 2.3    cpumem 4.11   gpumem 52.23  reserved 57.61 
tick 2     kimg 100.2     time 19m 25s      sec/tick 561.3   sec/kimg 11.22   maintenance 0.0    cpumem 4.11   gpumem 52.23  reserved 57.61 
tick 3     kimg 150.3     time 28m 46s      sec/tick 561.4   sec/kimg 11.22   maintenance 0.0    cpumem 4.11   gpumem 52.23  reserved 57.61 
tick 4     kimg 200.3     time 38m 08s      sec/tick 561.3   sec/kimg 11.22   maintenance 0.0    cpumem 4.11   gpumem 52.23  reserved 57.61 
tick 5     kimg 250.4     time 47m 29s      sec/tick 561.3   sec/kimg 11.22   maintenance 0.0    cpumem 4.11   gpumem 52.23  reserved 57.61 
tick 6     kimg 300.4     time 56m 50s      sec/tick 561.5   sec/kimg 11.22   maintenance 0.0    cpumem 4.11   gpumem 52.23  reserved 57.61 

Aborted!
