Loading datasets...
Constructing network...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...

EDMPrecond            Parameters  Buffers  Output shape      Datatype
---                   ---         ---      ---               ---     
model.map_noise       -           -        [8, 128]          float32 
model.map_layer0      66048       -        [8, 512]          float32 
model.map_layer1      262656      -        [8, 512]          float32 
model.enc.0_conv      839168      -        [8, 128, 96, 96]  float32 
model.enc.0_block0    71664512    -        [8, 128, 96, 96]  float32 
model.enc.0_block1    71664512    -        [8, 128, 96, 96]  float32 
model.enc.0_block2    71664512    -        [8, 128, 96, 96]  float32 
model.enc.0_block3    71664512    -        [8, 128, 96, 96]  float32 
model.enc.1_down      19252224    8        [8, 128, 48, 48]  float32 
model.enc.1_block0    57673472    -        [8, 256, 48, 48]  float32 
model.enc.1_block1    76809984    -        [8, 256, 48, 48]  float32 
model.enc.1_block2    76809984    -        [8, 256, 48, 48]  float32 
model.enc.1_block3    76809984    -        [8, 256, 48, 48]  float32 
model.enc.2_down      22349824    8        [8, 256, 24, 24]  float32 
model.enc.2_block0    22284032    -        [8, 256, 24, 24]  float32 
model.enc.2_block1    22284032    -        [8, 256, 24, 24]  float32 
model.enc.2_block2    22284032    -        [8, 256, 24, 24]  float32 
model.enc.2_block3    22284032    -        [8, 256, 24, 24]  float32 
model.enc.3_down      7669760     8        [8, 256, 12, 12]  float32 
model.enc.3_block0    7603968     -        [8, 256, 12, 12]  float32 
model.enc.3_block1    7603968     -        [8, 256, 12, 12]  float32 
model.enc.3_block2    7603968     -        [8, 256, 12, 12]  float32 
model.enc.3_block3    7603968     -        [8, 256, 12, 12]  float32 
model.enc.4_down      1378304     8        [8, 256, 6, 6]    float32 
model.enc.4_block0    1576192     -        [8, 256, 6, 6]    float32 
model.enc.4_block1    1576192     -        [8, 256, 6, 6]    float32 
model.enc.4_block2    1576192     -        [8, 256, 6, 6]    float32 
model.enc.4_block3    1576192     -        [8, 256, 6, 6]    float32 
model.enc.5_down      1378304     8        [8, 256, 3, 3]    float32 
model.enc.5_block0    1312512     -        [8, 256, 3, 3]    float32 
model.enc.5_block1    1312512     -        [8, 256, 3, 3]    float32 
model.enc.5_block2    1312512     -        [8, 256, 3, 3]    float32 
model.enc.5_block3    1312512     -        [8, 256, 3, 3]    float32 
model.dec.5_in0       1576192     -        [8, 256, 3, 3]    float32 
model.dec.5_in1       1312512     -        [8, 256, 3, 3]    float32 
model.dec.5_block0    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block1    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block2    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block3    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block4    2034176     -        [8, 256, 3, 3]    float32 
model.dec.4_up        1378304     8        [8, 256, 6, 6]    float32 
model.dec.4_block0    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block1    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block2    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block3    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block4    2297856     -        [8, 256, 6, 6]    float32 
model.dec.3_up        1378304     8        [8, 256, 12, 12]  float32 
model.dec.3_block0    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block1    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block2    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block3    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block4    11471360    -        [8, 256, 12, 12]  float32 
model.dec.2_up        7669760     8        [8, 256, 24, 24]  float32 
model.dec.2_block0    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block1    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block2    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block3    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block4    33491456    -        [8, 256, 24, 24]  float32 
model.dec.1_up        22349824    8        [8, 256, 48, 48]  float32 
model.dec.1_block0    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block1    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block2    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block3    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block4    96078080    -        [8, 256, 48, 48]  float32 
model.dec.0_up        76875776    8        [8, 256, 96, 96]  float32 
model.dec.0_block0    143312384   -        [8, 128, 96, 96]  float32 
model.dec.0_block1    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_block2    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_block3    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_block4    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_aux_norm  256         -        [8, 128, 96, 96]  float32 
model.dec.0_aux_conv  839043      -        [8, 3, 96, 96]    float32 
model                 1152        -        [8, 3, 96, 96]    float32 
<top-level>           -           -        [8, 3, 96, 96]    float32 
---                   ---         ---      ---               ---     
Total                 2248364035  80       -                 -       

Setting up optimizer...
Loading network weights from "ffhq-training-runs/00084-ffhq-160x160_ffhq-144x144_ffhq-128x128_ffhq-112x112_ffhq-96x96-uncond-ddpmpp-edm-gpus8-batch256-fp32/network-snapshot-035123.pkl"...
Loading training state from "ffhq-training-runs/00084-ffhq-160x160_ffhq-144x144_ffhq-128x128_ffhq-112x112_ffhq-96x96-uncond-ddpmpp-edm-gpus8-batch256-fp32/training-state-035123.pt"...
Training for 200000 kimg...

tick 0     kimg 35123.3   time 2m 31s       sec/tick 25.1    sec/kimg 97.95   maintenance 126.3  cpumem 12.79  gpumem 70.85  reserved 76.44 
tick 1     kimg 35148.3   time 7m 50s       sec/tick 307.7   sec/kimg 12.26   maintenance 11.4   cpumem 12.80  gpumem 66.02  reserved 76.59 
tick 2     kimg 35173.4   time 12m 30s      sec/tick 279.4   sec/kimg 11.14   maintenance 0.0    cpumem 12.80  gpumem 66.02  reserved 68.44 
tick 3     kimg 35198.5   time 17m 08s      sec/tick 277.7   sec/kimg 11.07   maintenance 0.0    cpumem 12.80  gpumem 66.02  reserved 68.44 
