Loading dataset...
Constructing network...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Input has shape: torch.Size([8, 3, 256, 256])
Has nan: False
/mnt/nvme/home/alex/repos/diffusion/edm/training/networks.py:166: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:31.)
  x_ft = torch.fft.rfft2(x)
Out shape at block 0_conv: torch.Size([8, 128, 256, 256])
Has nan: False
Out shape at block 0_block0: torch.Size([8, 128, 256, 256])
Has nan: True
Out shape at block 0_block1: torch.Size([8, 128, 256, 256])
Has nan: True
Out shape at block 0_block2: torch.Size([8, 128, 256, 256])
Has nan: True
Out shape at block 0_block3: torch.Size([8, 128, 256, 256])
Has nan: True
Out shape at block 1_down: torch.Size([8, 128, 128, 128])
Has nan: True
Out shape at block 1_block0: torch.Size([8, 256, 128, 128])
Has nan: True
Out shape at block 1_block1: torch.Size([8, 256, 128, 128])
Has nan: True
Out shape at block 1_block2: torch.Size([8, 256, 128, 128])
Has nan: True
Out shape at block 1_block3: torch.Size([8, 256, 128, 128])
Has nan: True
Out shape at block 2_down: torch.Size([8, 256, 64, 64])
Has nan: True
Out shape at block 2_block0: torch.Size([8, 256, 64, 64])
Has nan: True
Out shape at block 2_block1: torch.Size([8, 256, 64, 64])
Has nan: True
Out shape at block 2_block2: torch.Size([8, 256, 64, 64])
Has nan: True
Out shape at block 2_block3: torch.Size([8, 256, 64, 64])
Has nan: True
Out shape at block 3_down: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block0: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block1: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block2: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block3: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_in0: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_in1: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block0: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block1: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block2: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block3: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 3_block4: torch.Size([8, 256, 32, 32])
Has nan: True
Out shape at block 2_up: torch.Size([8, 256, 64, 64])
Has nan: True

Aborted!
