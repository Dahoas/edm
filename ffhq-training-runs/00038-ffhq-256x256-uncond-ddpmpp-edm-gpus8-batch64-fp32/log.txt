Loading dataset...
Constructing network...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...

EDMPrecond            Parameters  Buffers  Output shape        Datatype
---                   ---         ---      ---                 ---     
model.map_noise       -           -        [8, 128]            float32 
model.map_layer0      66048       -        [8, 512]            float32 
model.map_layer1      262656      -        [8, 512]            float32 
model.enc.0_conv      814592      -        [8, 128, 256, 256]  float32 
model.enc.0_block0    69567360    -        [8, 128, 256, 256]  float32 
model.enc.0_block1    69567360    -        [8, 128, 256, 256]  float32 
model.enc.0_block2    69567360    -        [8, 128, 256, 256]  float32 
model.enc.0_block3    69567360    -        [8, 128, 256, 256]  float32 
model.enc.1_down      18203648    8        [8, 128, 128, 128]  float32 
model.enc.1_block0    54527744    -        [8, 256, 128, 128]  float32 
model.enc.1_block1    72615680    -        [8, 256, 128, 128]  float32 
model.enc.1_block2    72615680    -        [8, 256, 128, 128]  float32 
model.enc.1_block3    72615680    -        [8, 256, 128, 128]  float32 
model.enc.2_down      20252672    8        [8, 256, 64, 64]    float32 
model.enc.2_block0    20186880    -        [8, 256, 64, 64]    float32 
model.enc.2_block1    20186880    -        [8, 256, 64, 64]    float32 
model.enc.2_block2    20186880    -        [8, 256, 64, 64]    float32 
model.enc.2_block3    20186880    -        [8, 256, 64, 64]    float32 
model.enc.3_down      1378304     8        [8, 256, 32, 32]    float32 
model.enc.3_block0    1312512     -        [8, 256, 32, 32]    float32 
model.enc.3_block1    1312512     -        [8, 256, 32, 32]    float32 
model.enc.3_block2    1312512     -        [8, 256, 32, 32]    float32 
model.enc.3_block3    1312512     -        [8, 256, 32, 32]    float32 
model.enc.4_down      1378304     8        [8, 256, 16, 16]    float32 
model.enc.4_block0    1576192     -        [8, 256, 16, 16]    float32 
model.enc.4_block1    1576192     -        [8, 256, 16, 16]    float32 
model.enc.4_block2    1576192     -        [8, 256, 16, 16]    float32 
model.enc.4_block3    1576192     -        [8, 256, 16, 16]    float32 
model.enc.5_down      1378304     8        [8, 256, 8, 8]      float32 
model.enc.5_block0    1312512     -        [8, 256, 8, 8]      float32 
model.enc.5_block1    1312512     -        [8, 256, 8, 8]      float32 
model.enc.5_block2    1312512     -        [8, 256, 8, 8]      float32 
model.enc.5_block3    1312512     -        [8, 256, 8, 8]      float32 
model.dec.5_in0       1576192     -        [8, 256, 8, 8]      float32 
model.dec.5_in1       1312512     -        [8, 256, 8, 8]      float32 
model.dec.5_block0    2034176     -        [8, 256, 8, 8]      float32 
model.dec.5_block1    2034176     -        [8, 256, 8, 8]      float32 
model.dec.5_block2    2034176     -        [8, 256, 8, 8]      float32 
model.dec.5_block3    2034176     -        [8, 256, 8, 8]      float32 
model.dec.5_block4    2034176     -        [8, 256, 8, 8]      float32 
model.dec.4_up        1378304     8        [8, 256, 16, 16]    float32 
model.dec.4_block0    2034176     -        [8, 256, 16, 16]    float32 
model.dec.4_block1    2034176     -        [8, 256, 16, 16]    float32 
model.dec.4_block2    2034176     -        [8, 256, 16, 16]    float32 
model.dec.4_block3    2034176     -        [8, 256, 16, 16]    float32 
model.dec.4_block4    2297856     -        [8, 256, 16, 16]    float32 
model.dec.3_up        1378304     8        [8, 256, 32, 32]    float32 
model.dec.3_block0    2034176     -        [8, 256, 32, 32]    float32 
model.dec.3_block1    2034176     -        [8, 256, 32, 32]    float32 
model.dec.3_block2    2034176     -        [8, 256, 32, 32]    float32 
model.dec.3_block3    2034176     -        [8, 256, 32, 32]    float32 
model.dec.3_block4    2034176     -        [8, 256, 32, 32]    float32 
model.dec.2_up        1378304     8        [8, 256, 64, 64]    float32 
model.dec.2_block0    30345728    -        [8, 256, 64, 64]    float32 
model.dec.2_block1    30345728    -        [8, 256, 64, 64]    float32 
model.dec.2_block2    30345728    -        [8, 256, 64, 64]    float32 
model.dec.2_block3    30345728    -        [8, 256, 64, 64]    float32 
model.dec.2_block4    30345728    -        [8, 256, 64, 64]    float32 
model.dec.1_up        20252672    8        [8, 256, 128, 128]  float32 
model.dec.1_block0    108988928   -        [8, 256, 128, 128]  float32 
model.dec.1_block1    108988928   -        [8, 256, 128, 128]  float32 
model.dec.1_block2    108988928   -        [8, 256, 128, 128]  float32 
model.dec.1_block3    108988928   -        [8, 256, 128, 128]  float32 
model.dec.1_block4    90835200    -        [8, 256, 128, 128]  float32 
model.dec.0_up        72681472    8        [8, 256, 256, 256]  float32 
model.dec.0_block0    139118080   -        [8, 128, 256, 256]  float32 
model.dec.0_block1    104350976   -        [8, 128, 256, 256]  float32 
model.dec.0_block2    104350976   -        [8, 128, 256, 256]  float32 
model.dec.0_block3    104350976   -        [8, 128, 256, 256]  float32 
model.dec.0_block4    104350976   -        [8, 128, 256, 256]  float32 
model.dec.0_aux_norm  256         -        [8, 128, 256, 256]  float32 
model.dec.0_aux_conv  814467      -        [8, 3, 256, 256]    float32 
model                 1152        -        [8, 3, 256, 256]    float32 
<top-level>           -           -        [8, 3, 256, 256]    float32 
---                   ---         ---      ---                 ---     
Total                 2058522627  80       -                   -       

Setting up optimizer...
Training for 200000 kimg...

tick 0     kimg 0.1       time 1m 05s       sec/tick 12.4    sec/kimg 193.76  maintenance 53.1   cpumem 3.30   gpumem 65.57  reserved 74.10 
Traceback (most recent call last):
  File "/mnt/nvme/home/alex/repos/diffusion/edm/train.py", line 250, in <module>
    main()
  File "/mnt/nvme/home/alex/.envs/diffusion/lib/python3.9/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/mnt/nvme/home/alex/.envs/diffusion/lib/python3.9/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/mnt/nvme/home/alex/.envs/diffusion/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/mnt/nvme/home/alex/.envs/diffusion/lib/python3.9/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "/mnt/nvme/home/alex/repos/diffusion/edm/train.py", line 245, in main
    training_loop.training_loop(**c)
  File "/mnt/nvme/home/alex/repos/diffusion/edm/training/training_loop.py", line 131, in training_loop
    loss.sum().mul(loss_scaling / batch_gpu_total).backward()
  File "/mnt/nvme/home/alex/.envs/diffusion/lib/python3.9/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/mnt/nvme/home/alex/.envs/diffusion/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 79.21 GiB total capacity; 76.00 GiB already allocated; 33.56 MiB free; 77.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
