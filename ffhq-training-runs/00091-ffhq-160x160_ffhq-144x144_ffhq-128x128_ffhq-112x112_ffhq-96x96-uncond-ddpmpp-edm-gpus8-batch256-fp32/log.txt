Loading datasets...
Constructing network...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...
Initializing fourier layer...

EDMPrecond            Parameters  Buffers  Output shape      Datatype
---                   ---         ---      ---               ---     
model.map_noise       -           -        [8, 128]          float32 
model.map_layer0      66048       -        [8, 512]          float32 
model.map_layer1      262656      -        [8, 512]          float32 
model.enc.0_conv      839168      -        [8, 128, 96, 96]  float32 
model.enc.0_block0    71664512    -        [8, 128, 96, 96]  float32 
model.enc.0_block1    71664512    -        [8, 128, 96, 96]  float32 
model.enc.0_block2    71664512    -        [8, 128, 96, 96]  float32 
model.enc.0_block3    71664512    -        [8, 128, 96, 96]  float32 
model.enc.1_down      19252224    8        [8, 128, 48, 48]  float32 
model.enc.1_block0    57673472    -        [8, 256, 48, 48]  float32 
model.enc.1_block1    76809984    -        [8, 256, 48, 48]  float32 
model.enc.1_block2    76809984    -        [8, 256, 48, 48]  float32 
model.enc.1_block3    76809984    -        [8, 256, 48, 48]  float32 
model.enc.2_down      22349824    8        [8, 256, 24, 24]  float32 
model.enc.2_block0    22284032    -        [8, 256, 24, 24]  float32 
model.enc.2_block1    22284032    -        [8, 256, 24, 24]  float32 
model.enc.2_block2    22284032    -        [8, 256, 24, 24]  float32 
model.enc.2_block3    22284032    -        [8, 256, 24, 24]  float32 
model.enc.3_down      7669760     8        [8, 256, 12, 12]  float32 
model.enc.3_block0    7603968     -        [8, 256, 12, 12]  float32 
model.enc.3_block1    7603968     -        [8, 256, 12, 12]  float32 
model.enc.3_block2    7603968     -        [8, 256, 12, 12]  float32 
model.enc.3_block3    7603968     -        [8, 256, 12, 12]  float32 
model.enc.4_down      1378304     8        [8, 256, 6, 6]    float32 
model.enc.4_block0    1576192     -        [8, 256, 6, 6]    float32 
model.enc.4_block1    1576192     -        [8, 256, 6, 6]    float32 
model.enc.4_block2    1576192     -        [8, 256, 6, 6]    float32 
model.enc.4_block3    1576192     -        [8, 256, 6, 6]    float32 
model.enc.5_down      1378304     8        [8, 256, 3, 3]    float32 
model.enc.5_block0    1312512     -        [8, 256, 3, 3]    float32 
model.enc.5_block1    1312512     -        [8, 256, 3, 3]    float32 
model.enc.5_block2    1312512     -        [8, 256, 3, 3]    float32 
model.enc.5_block3    1312512     -        [8, 256, 3, 3]    float32 
model.dec.5_in0       1576192     -        [8, 256, 3, 3]    float32 
model.dec.5_in1       1312512     -        [8, 256, 3, 3]    float32 
model.dec.5_block0    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block1    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block2    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block3    2034176     -        [8, 256, 3, 3]    float32 
model.dec.5_block4    2034176     -        [8, 256, 3, 3]    float32 
model.dec.4_up        1378304     8        [8, 256, 6, 6]    float32 
model.dec.4_block0    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block1    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block2    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block3    2034176     -        [8, 256, 6, 6]    float32 
model.dec.4_block4    2297856     -        [8, 256, 6, 6]    float32 
model.dec.3_up        1378304     8        [8, 256, 12, 12]  float32 
model.dec.3_block0    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block1    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block2    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block3    11471360    -        [8, 256, 12, 12]  float32 
model.dec.3_block4    11471360    -        [8, 256, 12, 12]  float32 
model.dec.2_up        7669760     8        [8, 256, 24, 24]  float32 
model.dec.2_block0    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block1    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block2    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block3    33491456    -        [8, 256, 24, 24]  float32 
model.dec.2_block4    33491456    -        [8, 256, 24, 24]  float32 
model.dec.1_up        22349824    8        [8, 256, 48, 48]  float32 
model.dec.1_block0    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block1    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block2    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block3    115280384   -        [8, 256, 48, 48]  float32 
model.dec.1_block4    96078080    -        [8, 256, 48, 48]  float32 
model.dec.0_up        76875776    8        [8, 256, 96, 96]  float32 
model.dec.0_block0    143312384   -        [8, 128, 96, 96]  float32 
model.dec.0_block1    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_block2    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_block3    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_block4    107496704   -        [8, 128, 96, 96]  float32 
model.dec.0_aux_norm  256         -        [8, 128, 96, 96]  float32 
model.dec.0_aux_conv  839043      -        [8, 3, 96, 96]    float32 
model                 1152        -        [8, 3, 96, 96]    float32 
<top-level>           -           -        [8, 3, 96, 96]    float32 
---                   ---         ---      ---               ---     
Total                 2248364035  80       -                 -       

Setting up optimizer...
Loading network weights from "ffhq-training-runs/00084-ffhq-160x160_ffhq-144x144_ffhq-128x128_ffhq-112x112_ffhq-96x96-uncond-ddpmpp-edm-gpus8-batch256-fp32/network-snapshot-035123.pkl"...
Loading training state from "ffhq-training-runs/00084-ffhq-160x160_ffhq-144x144_ffhq-128x128_ffhq-112x112_ffhq-96x96-uncond-ddpmpp-edm-gpus8-batch256-fp32/training-state-035123.pt"...
Training for 200000 kimg...

tick 0     kimg 35123.3   time 2m 29s       sec/tick 23.7    sec/kimg 92.58   maintenance 125.2  cpumem 12.77  gpumem 70.86  reserved 76.47 
tick 1     kimg 35148.3   time 7m 33s       sec/tick 294.3   sec/kimg 11.73   maintenance 10.2   cpumem 12.78  gpumem 66.03  reserved 76.21 
tick 2     kimg 35173.4   time 12m 14s      sec/tick 280.9   sec/kimg 11.20   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 3     kimg 35198.5   time 16m 53s      sec/tick 279.0   sec/kimg 11.12   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 4     kimg 35223.6   time 21m 35s      sec/tick 281.5   sec/kimg 11.22   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 5     kimg 35248.7   time 26m 15s      sec/tick 280.3   sec/kimg 11.17   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 6     kimg 35273.8   time 30m 56s      sec/tick 280.3   sec/kimg 11.17   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 7     kimg 35298.9   time 35m 37s      sec/tick 281.3   sec/kimg 11.21   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 8     kimg 35324.0   time 40m 16s      sec/tick 279.1   sec/kimg 11.12   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 9     kimg 35349.0   time 44m 57s      sec/tick 281.5   sec/kimg 11.22   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 10    kimg 35374.1   time 49m 37s      sec/tick 280.0   sec/kimg 11.16   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 11    kimg 35399.2   time 54m 18s      sec/tick 280.1   sec/kimg 11.16   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 12    kimg 35424.3   time 58m 58s      sec/tick 280.7   sec/kimg 11.19   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 13    kimg 35449.4   time 1h 03m 37s   sec/tick 279.0   sec/kimg 11.12   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 14    kimg 35474.5   time 1h 08m 19s   sec/tick 281.4   sec/kimg 11.22   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 15    kimg 35499.6   time 1h 12m 59s   sec/tick 280.1   sec/kimg 11.17   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 16    kimg 35524.7   time 1h 17m 39s   sec/tick 280.2   sec/kimg 11.17   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 17    kimg 35549.8   time 1h 22m 20s   sec/tick 280.8   sec/kimg 11.19   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 18    kimg 35574.8   time 1h 26m 59s   sec/tick 279.0   sec/kimg 11.12   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 19    kimg 35599.9   time 1h 31m 40s   sec/tick 281.5   sec/kimg 11.22   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 20    kimg 35625.0   time 1h 36m 21s   sec/tick 280.3   sec/kimg 11.17   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 21    kimg 35650.1   time 1h 41m 01s   sec/tick 280.3   sec/kimg 11.17   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 
tick 22    kimg 35675.2   time 1h 45m 42s   sec/tick 281.1   sec/kimg 11.20   maintenance 0.0    cpumem 12.78  gpumem 66.03  reserved 68.47 

Aborted!
